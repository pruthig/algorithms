Closest pair algorithm:

For 1-D - Sort the points according to the 1-Dimension and pick the smallest between the 2 values in the order.

ClosestPair of a set of points:
1. Divide the set into two equal sized parts by the line l, and recursively compute the minimal distance in each part.
2. Let d be the minimal of the two minimal distances.
3. Eliminate points that lie farther than d apart from l
4. Sort the remaining points according to their y-coordinates
5. Scan the remaining points in the y order and compute the distances of each point to its five neighbors.
6. If any of these distances is less than d then update d.

Steps 2-6 define the merging process which must be repeated logn times because this is a divide and conquer algortithm:
Step 2 takes O(1) time
Step 3 takes O(n) time
Step 4 is a sort that takes O(nlogn) time
Step 5 takes O(n) time (as we saw in the previous section)
Step 6 takes O(1) time

Master theorem:
Used to determine running time of recursive algorithms.
Defined as:

T(n) = a * T( n / b ) + O( n^d )  where
a -> Number of recursive calls
b -> Factor by which input problem is divided, e.g for merge sort it is 2
d -> Denotes the effort put while combining the solution.

a = b^d  ==>  O( (n^d)*logn )
b^d > a  ==>  O( n^d )
a > b^d  ==>  O( n^(logb^a) )

Effort put in recursion = c*n^d * ( (j = 0 to logb ) Σ ( (a / b^d )^j )


Quicksort Algorithm:
> Elegant and in place
> Practical with O(nlogn) time

Steps:
Choose a pivot
Run a loop so that all elements < pivot are to the left of the pivot and rest to the right
Quicksort runs in O(n^2) if sorted array is passed because only 1st half will be executed since 2 halfs are not divided evenly.
or we can call it as unbalanced split.
Efficiency:
Efficiency of Quicksort is O(nlogn). First, Big-Oh is the number of comparisons of elements in the given set.
For Quicksort if 'C' denotes the sum of  all comparisons:
C = (i=0 to n-1) Σ (j = i+1 to n)  Σ Sum[ Prob(i,j] ]    -  (1)                // where prob[i,j] is the probability that the elements a[i] and a[j] will be compared.
Let the elements be --> z(i) ... | ... z(j)
Now z(i) and z(j) will be compared only when any of these is selected as a pivot element, the probability of the same is - 2 / (j-i+1)
Putting this in Eqn. (1)


C = (i=0 to n-1) Σ (j = i+1 to n)  Σ Sum(2 / (j-i+1)) or
C = 2*n* Σ (j = i+1 to n) 1 / (j-i+1) or
C = 2*n*logn or
C = n*logn           - Q.E.D

Order Statistics:
Nearly a quicksort. It just that we are looking for 'i'th position and we recurse once either going to left or to right not on both sides.

T(n) = T(n/2) + O(n)  ==>  O(n)

 **************** Trees ***********************
 The diameter of a tree T is the largest of the following quantities:

* the diameter of T’s left subtree
* the diameter of T’s right subtree
* the longest path between leaves that goes through the root of T (this can be computed from the heights of the subtrees of T)
int lheight = height(tree->left);
int rheight = height(tree->right);
int ldiameter = diameter(tree->left);
int rdiameter = diameter(tree->right);
 
  return max(lheight + rheight + 1, max(ldiameter, rdiameter));

--> We can make an inorder traversal using Morris threaded tree in which each node has a pointer that points to its successor.
Algo as goes - with root as input node
D.S - a visited set
Mark current input node as visited and go to its left and repeat this step marking the left of the current node under consideration as visited.

--> Sum tree - Check if a given node is sum of its left and right subtrees
    boolean isSumTree(Node node) 
	{
        if (node == null || isLeaf(node))
            return true;
 
        int ls = 0, rs = 0;
 
		if (node.left != null)
			ls = isLeaf(node.left)? node.left.data: 2* node.left.data;
 
		if (node.right != null)
			rs = isLeaf(node.right)? node.right.data: 2 * node.right.data;
 
		return (node.data == ls + rs && isSumTree(node.left) && isSumTree(node.right));
    }

-->Populate inorder successor-
	Do reverse inorder traversal and keep track of previously visited node. so for each current node, do current_node->next = 
	previous visited node
-->




 ****************  Graphs *********************
 
 Minimum cut/Graph partition is a dividing graph in 2 so that there are minimum number of crossing edges.
 
 N defines the number of vertices and M defined the number of edges.
 M =  Ω(N) = O(N^2)
 
 BFS can be used to find shortest path in unweighted graph, for weighted we should use Dijkstra algorithm.
 * DFS cannot find the shortest path because
 
 
 Topological Ordering:
 It is an ordering of nodes in a graph such that :
 ( u, v ) є G ==> f(u) < f(v)
 Topological ordering of courses so that one can find the prerequisites for completing a course.
 Cyclic graph cannot have topological order.
 Algorithm - Find the sink vertex by doing DFS and assign that vertex an integer - n
 Loop through other vertices by decrementing the label number.
 DFS_LOOP(Graph G) {
 // Mark all unexplored.
 // cur_label = n
 // for each vertex v in G 
	// if v not explored
	// DFS(G, v);
 }
 DFS(Graph g, start_vertex s) {
 // mark s explored
 // for all edges from s -> v
	 // if v not explored
		// DFS(G, v)
 // f(s) = cur_label;
 // cur_lable--
 
 Kosaraju Algorithm :- To find the Strongly Connected Components of a directed graph. Choice of starting node matters a lot in this. To find this, we'll do DFS on reversed Graph which will find the ordering of nodes in range 1 to n and then will use that ordering in decreasing order to find respective SCC. So, it is 2 step algorithm.
 1. Find finishing time of each node by doing DFS on reversed Graph. 
	for(n->1)
		//DFS(i)
	DFS(i)
		for(all i, j)
		  //DFS(j)
		finishing_time++
		f(j) = finishing_time;

 2. Use that ordering and DFS on original graph in order from n to 1
 
 
* Any acyclic connected graph is a tree
 
 ************** Strings **************************
 
 Find next permutation of string:
 https://www.nayuki.io/page/next-lexicographical-permutation-algorithm
* Find the highest index i such that s[i] < s[i+1]. If no such index exists, the permutation is the last permutation.
* Find the highest index j > i such that s[j] > s[i]. Such a j must exist, since i+1 is such an index.
* Swap s[i] with s[j].
* Reverse the order of all of the elements after index i till the last element.


 
 



